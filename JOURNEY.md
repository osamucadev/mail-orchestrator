# Building Mail Orchestrator  
## A guided system design, not a prompt experiment

This project did not start as an idea generated by an AI.  
It started as something worse and better at the same time:  
a half built idea abandoned in a folder for almost seven months.

Mail Orchestrator existed as a mental model long before it existed as code.  
The problem was clear, the motivation was clear, but the execution kept being postponed.

The difference this time was not “using AI to build faster”.  
The difference was using an assistant as hands, while keeping the brain fully human.

This document narrates how this project was built so far, through conscious technical decisions, tradeoffs, bugs, refactors, and learning moments.

---

## Roles and mental model

Before any code, there was a rule.

* I define the problem.
* I define the constraints.
* I define the taste.
* I define what matters and what does not.

The assistant does not invent direction.  
It executes, challenges, and accelerates.

This is closer to pair programming than to code generation.

One brain.  
One tireless pair of hands.

---

## The problem was never “send emails”

Sending emails is easy. Gmail already does that.

The real problem was orchestration:

* Tracking sent emails locally.
* Knowing who replied and who did not.
* Understanding time as a signal, not as a timestamp.
* Reusing messages without losing context.
* Designing something that works locally, but does not paint itself into a corner.

This immediately ruled out shortcuts.

No third party SaaS.  
No cloud dependency at first.  
No magic abstraction.

Just a system that can be reasoned about.

---

## Architecture as a first class decision

Very early, the project was split intentionally.

* Frontend: vanilla HTML, SCSS and JavaScript.
* Backend: FastAPI with explicit REST contracts.
* Database: SQLite with Alembic migrations.
* Integration: Gmail API via OAuth.

This was not about fashion.  
It was about controllability.

Every layer could be inspected.  
Every failure could be reasoned about.

Swagger was not a nice to have.  
It was mandatory, because APIs are products too.

---

## Commit driven development as learning strategy

The project evolved commit by commit, always with something runnable.

Each commit had two goals:

* Add a concrete capability.
* Teach something new, especially on the Python side.

Examples:

* Understanding how FastAPI actually parses multipart data.
* Learning how Gmail expects RFC 2822 messages encoded.
* Seeing how OAuth failures really look in practice.
* Understanding MIME structure instead of hand waving about “attachments”.

This was not tutorial driven learning.  
It was problem driven learning.

---

## Bugs as design feedback, not annoyances

Several bugs were not accidents.  
They were symptoms of missing design decisions.

### Emoji thresholds behaving unexpectedly

This exposed an implicit assumption:

Were thresholds lower bounds or upper bounds?

The system originally treated red as a fallback.  
The expectation was that all four values mattered.

Fixing this forced an explicit rule:

* Each threshold is an upper bound.
* Order matters.
* The UI preview and backend logic must match.

This was not a bug fix.  
It was a clarification of semantics.

---

### Resend that did not actually resend

The resend feature initially duplicated database rows without calling Gmail.

Technically correct.  
Functionally wrong.

This exposed an important rule:

If the system claims something happened, the external world must agree.

The resend flow was refactored to:

* Fetch original email.
* Send again via Gmail API.
* Persist new message and thread IDs.

Local truth and external truth were aligned again.

---

### Attachments that “looked” sent but never arrived

The UI suggested success.  
The email arrived empty.

Root cause was simple:

Metadata is not data.

Until real files were uploaded and stored locally, nothing could be attached.

This forced a shift:

* JSON was no longer enough.
* Multipart became necessary.
* python-multipart became a dependency.
* File lifecycle became explicit.

The system got more complex, but also more honest.

---

### Inline images: the most instructive problem

This was the hardest and most educational part.

Three different worlds collided:

* Browsers do not understand `cid:`.
* Email clients do.
* Gmail requires proper MIME related structure.

The solution required understanding, not guessing.

Frontend responsibilities:

* Store pasted images as data URLs.
* Generate stable content IDs.
* Replace `cid:` with data URLs for preview only.
* Convert data URLs to binary blobs for sending.

Backend responsibilities:

* Accept inline images via multipart.
* Persist files locally.
* Attach them as related MIME parts.
* Respect content IDs exactly.

The result:

* Preview works in the browser.
* Images render correctly in Gmail.
* The system behaves like a real email client.

This alone justified the project.

---

## AI as an amplifier, not an author

At no point did the assistant decide what the product should be.

What it did:

* Generate boilerplate faster than I would.
* Recall edge cases I might forget.
* Explain tradeoffs clearly.
* Adjust code precisely when bugs appeared.

What it did not do:

* Choose architecture.
* Decide UX priorities.
* Define constraints.
* Lower the bar for quality.

This matters.

Because the final result is not “AI code”.  
It is authored software, built with assistance.

---

## Taking a project out of the drawer

This project sat unused for months because starting felt heavy.

Using an assistant changed the cost of starting, not the responsibility of thinking.

Once momentum existed, the project stopped being hypothetical.

It became:

* A working system.
* A learning environment.
* A portfolio artifact.
* A proof of technical taste.

---

## Current state and next steps

At this point, Mail Orchestrator can:

* Authenticate with Gmail via OAuth.
* Send real emails with text, HTML, attachments and inline images.
* Track sent emails locally.
* Detect replies via Gmail threads.
* Represent time visually with meaningful signals.
* Run fully local with migrations and clear structure.

Future work is intentionally left visible:

* Follow up chains.
* Scheduled sends.
* Multi account support.
* Optional online deployment.

Not because it is unfinished.  
But because good systems always leave room to grow.

---

## Final note

This repository is not about showing that I can write code.

It is about showing how I think about systems.

The assistant helped me type faster.  
The decisions were mine.

That distinction is the whole point.
